family = binomial(link=logit), data = train)
print(summary(model.logistic))
#ANOVA
model.logistic.2 <- update(model.logistic, . ~ . - as.numeric(moves) - usage - as.factor(nonpub) - as.factor(reach.out) - as.factor(card))
anova(model.logistic.2, model.logistic, test="Chisq")
# Parameter Estimates
round(exp(cbind(Estimate=coef(model.logistic), confint(model.logistic))), 2)
# get predictions from model
predict.train.logistic <- predict(model.logistic, type = "response")
predict.test.logistic <- predict(model.logistic, test, type = "response")
train.logistic.pred <- prediction(predict.train.logistic, train$pick)
train.logistic.roc <- performance(train.logistic.pred, "tpr","fpr")
train.logistic.auc <- (performance(train.logistic.pred, "auc"))@y.values
test.logistic.pred <- prediction(predict.test.logistic, test$pick)
test.logistic.roc <- performance(test.logistic.pred, "tpr","fpr")
test.logistic.auc <- (performance(test.logistic.pred, "auc"))@y.values
# plot the ROC curves
plot(train.logistic.roc, col = "darkgreen", main = "ROC Curves for Logistic Regression Model")
plot(test.logistic.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Train: AUC=", round(train.logistic.auc[[1]], digits=3))
test.legend <- paste("Test : AUC=", round(test.logistic.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# LR Confusion matrix
predict.train.logistic.df<-data.frame(as.numeric(levels(train$pickdigit)[train$pickdigit]), as.numeric(predict.train.logistic))
names(predict.train.logistic.df)[names(predict.train.logistic.df)=="as.numeric.levels.train.pickdigit..train.pickdigit.."]<-"dep_var"
names(predict.train.logistic.df)[names(predict.train.logistic.df)=="as.numeric.predict.train.logistic."]<-"score"
confusion_matrix(predict.train.logistic.df, cutoff=0.3) # higher cutoffs than default of .5 in response score
# Random Forest
set.seed(9999)  # for reproducibility
MyModelSpec <- {pick ~ income + moves + age + education + employment + usage + nonpub + reach.out + card}
model.rf <- randomForest(MyModelSpec, mtry = 3, data = train)
print(summary(model.rf))
predict.train.rf <- predict(model.rf, type = "prob")[,2]
predict.test.rf <- predict(model.rf, test, type = "prob")[,2]
train.rf.pred <- prediction(predict.train.rf, train$pick)
train.rf.roc <- performance(train.rf.pred, "tpr","fpr")
train.rf.auc <- (performance(train.rf.pred, "auc"))@y.values
test.rf.pred <- prediction(predict.test.rf, test$pick)
test.rf.roc <- performance(test.rf.pred, "tpr","fpr")
test.rf.auc <- (performance(test.rf.pred, "auc"))@y.values
# plot the ROC curves
plot(train.rf.roc, col = "darkgreen", main = "ROC Curves for Random Forest Model")
plot(test.rf.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Train: AUC=", round(train.rf.auc[[1]], digits=3))
test.legend <- paste("Test : AUC=", round(test.rf.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# RF Confusion matrix
train.rf.pred.df<-data.frame(as.numeric(levels(train$pickdigit)[train$pickdigit]), as.numeric(predict.train.rf))
names(train.rf.pred.df)[names(train.rf.pred.df)=="as.numeric.levels.train.pickdigit..train.pickdigit.."]<-"dep_var"
names(train.rf.pred.df)[names(train.rf.pred.df)=="as.numeric.predict.train.rf."]<-"score"
confusion_matrix(train.rf.pred.df, cutoff=0.3) # higher cutoffs than default of .5 in response score
# ROC Comparison
# plot the ROC curves
plot(test.logistic.roc, col = "darkgreen", main = "ROC Curves for ATT")
plot(test.rf.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Logistic: AUC=", round(test.logistic.auc[[1]], digits=3))
test.legend <- paste("RF: AUC=", round(test.rf.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# PREDICT 412 Logistic Regression and Random Forest Demo with ROC curves
library(MMST)
library(ROCR)
library(randomForest)
library(plyr)
# Helper function
#' Plot a confusion matrix for a given prediction set, and return the table.
#'
#' @param dataframe data.frame. Must contain \code{score} and \code{dep_var}
#'    columns. The confusion matrix will be calculated for these values.
#'    The mentioned columns must both be numeric.
#' @param cutoff numeric. The cutoff at which to assign numbers greater a 1
#'    for prediction purposes, and 0 otherwise. The default is 0.5.
#' @param plot.it logical. Whether or not to plot the confusion matrix as a
#'    four fold diagram. The default is \code{TRUE}.
#' @param xlab character. The labels for the rows (\code{dep_var}). The default
#'    is \code{c("dep_var = 0", "dep_var = 1")}.
#' @param ylab character. The labels for the rows (\code{score}). The default
#'    is \code{c("score = 0", "score = 1")}.
#' @param title character. The title for the fourfoldplot, if it is graphed.
#' @return a table. The confusion matrix table.
confusion_matrix <- function(dataframe, cutoff = 0.2, plot.it = TRUE,
xlab = c("ATT = NO", "ATT = YES"),
ylab = c("Predicted = 0", "Predicted = 1"), title = NULL) {
stopifnot(is.data.frame(dataframe) &&
all(c('score', 'dep_var') %in% colnames(dataframe)))
stopifnot(is.numeric(dataframe$score) && is.numeric(dataframe$dep_var))
dataframe$score <- ifelse(dataframe$score <= cutoff, 0, 1)
categories <- dataframe$score * 2 + dataframe$dep_var
confusion <- matrix(tabulate(1 + categories, 4), nrow = 2)
colnames(confusion) <- ylab
rownames(confusion) <- xlab
if (plot.it) fourfoldplot(confusion, color = c("#99CC99", "#CC6666"),
conf.level = 0, margin = 1, main = title)
confusion
}
# Read the ATT data set and remove rows with NAs
att<-read.csv(file.choose(), strip.white=TRUE, na.strings=c("", " "))
att<-na.omit(att)
# Recast variables as factors
att$pickdigit <- revalue(att$pick, c("OCC"=0, "ATT"=1))
str(att$pick)
#divide the data into training and test sets 70/30
set.seed(1234)
integer.splitter <- runif(nrow(att))
integer.splitter <- ifelse(integer.splitter <= 0.7,1,0) # split data 70/30 training test
train <- att[which(integer.splitter == 1),]
test <- att[which(integer.splitter == 0),]
# specify the form of the model to be used in various methods
#MyModelSpec <- {pickdigit ~ as.factor(income) + as.numeric(moves) + as.factor(age) + as.factor(education) + as.factor(employment) + usage + as.factor(nonpub) + as.factor(reach.out) + as.factor(card)}
# pruning steps
#MyModelSpec <- {pickdigit ~ as.numeric(moves) + as.factor(age) + as.factor(education) + as.factor(employment) + usage + as.factor(nonpub) + as.factor(reach.out) + as.factor(card)}
#MyModelSpec <- {pickdigit ~ as.numeric(moves) + as.factor(education) + as.factor(employment) + usage + as.factor(nonpub) + as.factor(reach.out) + as.factor(card)}
#MyModelSpec <- {pickdigit ~ as.numeric(moves) + as.factor(employment) + usage + as.factor(nonpub) + as.factor(reach.out) + as.factor(card)}
MyModelSpec <- {pickdigit ~ as.numeric(moves) + usage + as.factor(nonpub) + as.factor(reach.out) + as.factor(card)}
# fit model logistic regression with a few of the explanatory variables for demo
model.logistic <- glm(MyModelSpec,
family = binomial(link=logit), data = train)
print(summary(model.logistic))
#ANOVA
model.logistic.2 <- update(model.logistic, . ~ . - as.numeric(moves) - usage - as.factor(nonpub) - as.factor(reach.out) - as.factor(card))
anova(model.logistic.2, model.logistic, test="Chisq")
# Parameter Estimates
round(exp(cbind(Estimate=coef(model.logistic), confint(model.logistic))), 2)
# get predictions from model
predict.train.logistic <- predict(model.logistic, type = "response")
predict.test.logistic <- predict(model.logistic, test, type = "response")
train.logistic.pred <- prediction(predict.train.logistic, train$pick)
train.logistic.roc <- performance(train.logistic.pred, "tpr","fpr")
train.logistic.auc <- (performance(train.logistic.pred, "auc"))@y.values
test.logistic.pred <- prediction(predict.test.logistic, test$pick)
test.logistic.roc <- performance(test.logistic.pred, "tpr","fpr")
test.logistic.auc <- (performance(test.logistic.pred, "auc"))@y.values
# plot the ROC curves
plot(train.logistic.roc, col = "darkgreen", main = "ROC Curves for Logistic Regression Model")
plot(test.logistic.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Train: AUC=", round(train.logistic.auc[[1]], digits=3))
test.legend <- paste("Test : AUC=", round(test.logistic.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# LR Confusion matrix
predict.test.logistic.df<-data.frame(as.numeric(levels(test$pickdigit)[test$pickdigit]), as.numeric(predict.test.logistic))
names(predict.test.logistic.df)[names(predict.test.logistic.df)=="as.numeric.levels.test.pickdigit..test.pickdigit.."]<-"dep_var"
names(predict.test.logistic.df)[names(predict.test.logistic.df)=="as.numeric.predict.test.logistic."]<-"score"
confusion_matrix(predict.test.logistic.df, cutoff=0.3) # higher cutoffs than default of .5 in response score
# Random Forest
set.seed(9999)  # for reproducibility
MyModelSpec <- {pick ~ income + moves + age + education + employment + usage + nonpub + reach.out + card}
model.rf <- randomForest(MyModelSpec, mtry = 3, data = train)
print(summary(model.rf))
predict.train.rf <- predict(model.rf, type = "prob")[,2]
predict.test.rf <- predict(model.rf, test, type = "prob")[,2]
train.rf.pred <- prediction(predict.train.rf, train$pick)
train.rf.roc <- performance(train.rf.pred, "tpr","fpr")
train.rf.auc <- (performance(train.rf.pred, "auc"))@y.values
test.rf.pred <- prediction(predict.test.rf, test$pick)
test.rf.roc <- performance(test.rf.pred, "tpr","fpr")
test.rf.auc <- (performance(test.rf.pred, "auc"))@y.values
# plot the ROC curves
plot(train.rf.roc, col = "darkgreen", main = "ROC Curves for Random Forest Model")
plot(test.rf.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Train: AUC=", round(train.rf.auc[[1]], digits=3))
test.legend <- paste("Test : AUC=", round(test.rf.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# RF Confusion matrix
test.rf.pred.df<-data.frame(as.numeric(levels(test$pickdigit)[test$pickdigit]), as.numeric(test.train.rf))
names(test.rf.pred.df)[names(test.rf.pred.df)=="as.numeric.levels.test.pickdigit..test.pickdigit.."]<-"dep_var"
names(test.rf.pred.df)[names(test.rf.pred.df)=="as.numeric.predict.test.rf."]<-"score"
confusion_matrix(test.rf.pred.df, cutoff=0.3) # higher cutoffs than default of .5 in response score
# ROC Comparison
# plot the ROC curves
plot(test.logistic.roc, col = "darkgreen", main = "ROC Curves for ATT")
plot(test.rf.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Logistic: AUC=", round(test.logistic.auc[[1]], digits=3))
test.legend <- paste("RF: AUC=", round(test.rf.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# RF Confusion matrix
test.rf.pred.df<-data.frame(as.numeric(levels(test$pickdigit)[test$pickdigit]), as.numeric(predict.test.rf))
names(test.rf.pred.df)[names(test.rf.pred.df)=="as.numeric.levels.test.pickdigit..test.pickdigit.."]<-"dep_var"
names(test.rf.pred.df)[names(test.rf.pred.df)=="as.numeric.predict.test.rf."]<-"score"
confusion_matrix(train.rf.pred.df, cutoff=0.3) # higher cutoffs than default of .5 in response score
confusion_matrix(test.rf.pred.df, cutoff=0.3) # higher cutoffs than default of .5 in response score
# Workforce Scheduling for Anonymous Bank Call Center (R)
library(lubridate)  # date functions
library(grid)  # graphics utilities needed for split-plotting
library(ggplot2)  # graphics package with ribbon plot
library(queueing)  # queueing functions, including Erlang C
library(lpSolve)  # linear programming package
install.packages("lubridate")
install.packages("queueing")
install.packages("lpSolve")
library(lubridate)  # date functions
library(grid)  # graphics utilities needed for split-plotting
library(ggplot2)  # graphics package with ribbon plot
library(queueing)  # queueing functions, including Erlang C
library(lpSolve)  # linear programming package
# Game-day Simulator for Baseball (R)
library(lattice)  # graphics package for probability matrix visual
simulator <- function(home_mean,away_mean,niterations) {
# input runs scored means, output probability of winning for home team
set.seed(1234)  # set to obtain reproducible results
away_game_score <- numeric(niterations)
home.game.score <- numeric(niterations)
home_win <- numeric(niterations)
i <- 1
while (i < niterations + 1) {
away_game_score[i] <- rnbinom(1,mu=away_mean, size = 4)
home.game.score[i] <- rnbinom(1,mu=home_mean, size = 4)
if(away_game_score[i] > home.game.score[i]) home_win[i] <- 1
if(away_game_score[i] > home.game.score[i] ||
away_game_score[i] < home.game.score[i]) i <- i + 1
}
n_home_win <- sum(home_win)
n_home_win/niterations  # return probability of away team winning
}
niterations <- 100000  # use smaller number for testing
# probability matrix for results... home team is rows, away team is columns
probmat <- matrix(data = NA, nrow = 9, ncol = 9,
dimnames = list(c(as.character(1:9)), c(as.character(1:9))))
for (index_home in 1:9)
for (index_away in 1:9)
if (index_home != index_away) {
probmat[index_home,index_away] <-
simulator(index_home, index_away, niterations)
}
pdf(file = "fig_sports_analytics_prob_matrix.pdf", width = 8.5, height = 8.5)
x <- rep(1:nrow(probmat),times=ncol(probmat))
y <- NULL
for (i in 1:ncol(probmat)) y <- c(y,rep(i,times=nrow(probmat)))
probtext <- sprintf("%0.3f", as.numeric(probmat))  # fixed format 0.XXX
text_data_frame <- data.frame(x, y, probtext)
text_data_frame$probtext <- as.character(text_data_frame$probtext)
text_data_frame$probtext <- ifelse((text_data_frame$probtext == "NA"),
NA,text_data_frame$probtext)  # define diagonal cells as missing
text_data_frame <- na.omit(text_data_frame)  # diagonal cells
print(levelplot(probmat, cuts = 25, tick.number = 9,
col.regions=colorRampPalette(c("violet", "white", "light blue")),
xlab = "Visiting Team Runs Expected",
ylab = "Home Team Runs Expected",
panel = function(...) {
panel.levelplot(...)
panel.text(text_data_frame$x, text_data_frame$y,
labels = text_data_frame$probtext)
}))
dev.off()
# Suggestion for the student: Develop simulators for football or basketball.
View(text_data_frame)
tcf<-read.csv(file.choose(), stringsAsFactors=TRUE)
fbs<-subset(tcf, FCS == 'NO')
allw<-lm(MOV ~ AWAY + HOME + MONTH + TEMP + WIND + NIGHT + RIVALRY, data=fbs)
summary(allw)
allw.p<-lm(MOV ~ AWAY + HOME + TEMP + WIND + NIGHT + RIVALRY, data=fbs)
summary(allw.p)
tcf.new<-read.csv(file.choose(), stringsAsFactors=TRUE)
View(tcf.new)
fbs$pred<-predict(allw.p, data=fbs, type="response")
tcf.new$pred<-predict(allw.p, tcf.new, type="response")
fbs$WIN<-ifelse(fbs$MOV > 0, 1, 0)
win.glm<-glm(WIN ~ AWAY + HOME + TEMP + WIND + NIGHT + RIVALRY,
data=fbs, family=binomial(link=logit))
summary(win.glm)
round(exp(cbind(Estimate=coef(win.glm),confint(win.glm))),2)
tcf.new$WIN<-predict(win.glm, tcf.new, type="response")
View(fbs)
View(tcf.new)
tcf.new$TEMP[tcf.new["TEMP"] == 22] <- 10
tcf.new$pred<-predict(allw.p, tcf.new, type="response")
tcf.new$WIN<-predict(win.glm, tcf.new, type="response")
View(tcf.new)
setwd("~/Dropbox/Northwestern MSPA/PREDICT412/Group Project/Code/R Code/Matt H:Pred412-GroupProject/Data")
library(MMST)
library(ROCR)
library(randomForest)
library(plyr)
library(rpart)
# Helper function
#' Plot a confusion matrix for a given prediction set, and return the table.
#'
#' @param dataframe data.frame. Must contain \code{score} and \code{dep_var}
#'    columns. The confusion matrix will be calculated for these values.
#'    The mentioned columns must both be numeric.
#' @param cutoff numeric. The cutoff at which to assign numbers greater a 1
#'    for prediction purposes, and 0 otherwise. The default is 0.5.
#' @param plot.it logical. Whether or not to plot the confusion matrix as a
#'    four fold diagram. The default is \code{TRUE}.
#' @param xlab character. The labels for the rows (\code{dep_var}). The default
#'    is \code{c("dep_var = 0", "dep_var = 1")}.
#' @param ylab character. The labels for the rows (\code{score}). The default
#'    is \code{c("score = 0", "score = 1")}.
#' @param title character. The title for the fourfoldplot, if it is graphed.
#' @return a table. The confusion matrix table.
confusion_matrix <- function(dataframe, cutoff = 0.2, plot.it = TRUE,
xlab = c("ILLICIT DRUG ABUSER = NO", "ILLICIT DRUG ABUSER = YES"),
ylab = c("Predicted = 0", "Predicted = 1"), title = NULL) {
stopifnot(is.data.frame(dataframe) &&
all(c('score', 'dep_var') %in% colnames(dataframe)))
stopifnot(is.numeric(dataframe$score) && is.numeric(dataframe$dep_var))
dataframe$score <- ifelse(dataframe$score <= cutoff, 0, 1)
categories <- dataframe$score * 2 + dataframe$dep_var
confusion <- matrix(tabulate(1 + categories, 4), nrow = 2)
colnames(confusion) <- ylab
rownames(confusion) <- xlab
if (plot.it) fourfoldplot(confusion, color = c("#CC6666", "#99CC99"),
conf.level = 0, margin = 1, main = title)
confusion
}
load("Final Data- Drug and Health Survey Data.RData")
surveydf.clean<-subset(surveydf, select = c(ABUSEILL, EDUCCAT2, POVERTY2, GOVTPROG, IRSEX, IRMARIT, EMPSTATY))
surveydf.clean<-na.omit(surveydf.clean)
# Create a simple logistic regression model with some demographics
illicit.drug.model <- glm(ABUSEILL ~ EDUCCAT2 + POVERTY2 +
GOVTPROG + IRSEX + IRMARIT + EMPSTATY,
data = surveydf.clean,
family = binomial(link=logit))
summary(illicit.drug.model)
round(exp(cbind(Estimate=coef(illicit.drug.model),confint(illicit.drug.model))),2)
#ANOVA
illicit.drug.model.2 <- update(illicit.drug.model, . ~ . - EDUCCAT2 - POVERTY2 - GOVTPROG - IRSEX - IRMARIT - EMPSTATY)
anova(illicit.drug.model.2, illicit.drug.model, test="Chisq")
# get predictions from model
surveydf.clean$score <- predict(illicit.drug.model, data=surveydf.clean, type = "response")
# LR Confusion matrix
surveydf.clean$dep_var<-revalue(surveydf.clean$ABUSEILL, c("(1) Yes (Any source variable above=1 & DEPNDILL=0)"=1, "(0) No/Unknown (Otherwise)"=0))
surveydf.clean$dep_var<-as.numeric(as.character(surveydf.clean$dep_var))
confusion_matrix(surveydf.clean, cutoff=0.015) # lower cutoffs than default of .5 in response score
# TRAIN/TEST REGIMEN
#divide the data into training and test sets 70/30
set.seed(1234)
integer.splitter <- runif(nrow(surveydf.clean))
integer.splitter <- ifelse(integer.splitter <= 0.7,1,0) # split data 70/30 training test
train <- surveydf.clean[which(integer.splitter == 1),]
test <- surveydf.clean[which(integer.splitter == 0),]
# MAIN EFFECTS MODEL
MyModelSpec <- {ABUSEILL ~ EDUCCAT2 + POVERTY2 + GOVTPROG + IRSEX + IRMARIT + EMPSTATY}
# fit model logistic regression with a few of the explanatory variables for demo
model.logistic <- glm(MyModelSpec,
family = binomial(link=logit), data = train)
print(summary(model.logistic))
# get predictions from model
predict.train.logistic <- predict(model.logistic, type = "response")
predict.test.logistic <- predict(model.logistic, test, type = "response")
train.logistic.pred <- prediction(predict.train.logistic, train$ABUSEILL)
train.logistic.roc <- performance(train.logistic.pred, "tpr","fpr")
train.logistic.auc <- (performance(train.logistic.pred, "auc"))@y.values
test.logistic.pred <- prediction(predict.test.logistic, test$ABUSEILL)
test.logistic.roc <- performance(test.logistic.pred, "tpr","fpr")
test.logistic.auc <- (performance(test.logistic.pred, "auc"))@y.values
# plot the ROC curves
plot(train.logistic.roc, col = "darkgreen", main = "ROC Curves for Logistic Regression Model")
plot(test.logistic.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Train: AUC=", round(train.logistic.auc[[1]], digits=3))
test.legend <- paste("Test : AUC=", round(test.logistic.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# Random Forest Method
set.seed(9999)  # for reproducibility
# Subset data frame for RF
surveydf.rf<-subset(surveydf, select = c(ABUSEILL, ABUSEALC, GRSKD4_5, GRSKD5WK, DEPNDMRJ, ABUSEMRJ, GRSKMOCC, GRSKMREG, ABUSEIEM, ABILLALC, ABILANAL, DEPNDILL, DEPNDIEM, DPILLALC, DPILANAL, TXILALEV, ALCTRMT, ILLTRMT, TXILLALC, TXILANAL, TXLTILL2, AMHTXRC3, DRIVALD2, PAROL, PROB, ANXDLIF, DEPRSLIF, AMDELT, CATAGE, CATAG3, EDUCCAT2, POVERTY2, GOVTPROG, IRSEX, IRMARIT, EMPSTATY, COUTYP2, BOOKED))
surveydf.rf<-na.omit(surveydf.rf)
# divide into test and train
integer.splitter <- runif(nrow(surveydf.rf))
integer.splitter <- ifelse(integer.splitter <= 0.7,1,0) # split data 70/30 training test
train <- surveydf.rf[which(integer.splitter == 1),]
test <- surveydf.rf[which(integer.splitter == 0),]
MyModelRFSpec = {ABUSEILL~ABUSEALC+GRSKD4_5+GRSKD5WK+DEPNDMRJ+ABUSEMRJ+GRSKMOCC+GRSKMREG+ABUSEIEM+ABILLALC+ABILANAL+DEPNDILL+DEPNDIEM+DPILLALC+DPILANAL+TXILALEV+ALCTRMT+ILLTRMT+TXILLALC+TXILANAL+TXLTILL2+AMHTXRC3+DRIVALD2+PAROL+PROB+ANXDLIF+DEPRSLIF+AMDELT+CATAGE+CATAG3+EDUCCAT2+POVERTY2+GOVTPROG+IRSEX+IRMARIT+EMPSTATY+COUTYP2+BOOKED}
MyModelRFSpec = {ABUSEILL~ABUSEALC+ABUSEMRJ+ABUSEIEM+ABILLALC+ABILANAL+DEPNDILL+EDUCCAT2+EMPSTATY}
model.rf <- randomForest(MyModelRFSpec, mtry = 3, data = train)
print(summary(model.rf))
print(model.rf$importance)
predict.train.rf <- predict(model.rf, type = "prob")[,2]
predict.test.rf <- predict(model.rf, test, type = "prob")[,2]
train.rf.pred <- prediction(predict.train.rf, train$ABUSEILL)
train.rf.roc <- performance(train.rf.pred, "tpr","fpr")
train.rf.auc <- (performance(train.rf.pred, "auc"))@y.values
test.rf.pred <- prediction(predict.test.rf, test$ABUSEILL)
test.rf.roc <- performance(test.rf.pred, "tpr","fpr")
test.rf.auc <- (performance(test.rf.pred, "auc"))@y.values
# plot the ROC curves
plot(train.rf.roc, col = "darkgreen", main = "ROC Curves for Random Forest Model")
plot(test.rf.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Train: AUC=", round(train.rf.auc[[1]], digits=3))
test.legend <- paste("Test : AUC=", round(test.rf.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# RF Confusion matrix
test.rf.pred.df<-data.frame(as.numeric(levels(test$pickdigit)[test$pickdigit]), as.numeric(predict.test.rf))
names(test.rf.pred.df)[names(test.rf.pred.df)=="as.numeric.levels.test.pickdigit..test.pickdigit.."]<-"dep_var"
train$dep_var<-revalue(train$ABUSEILL, c("(1) Yes (Any source variable above=1 & DEPNDILL=0)"=1, "(0) No/Unknown (Otherwise)"=0))
train$dep_var<-as.numeric(as.character(train$dep_var))
train$score <- predict(model.rf, type = "prob")[,2]
confusion_matrix(train, cutoff=0.98) # higher cutoffs than default of .5 in response score
model.logistic.2 <- glm(MyModelRFSpec,
family = binomial(link=logit), data = train)
print(summary(model.logistic.2))
# Coefficients
round(exp(cbind(Estimate=coef(model.logistic.2),confint(model.logistic.2))),2)
MyModelRFSpec = {ABUSEILL~ABUSEALC+ABUSEMRJ+ABUSEIEM+ABILLALC+ABILANAL+DEPNDILL+EDUCCAT2+EMPSTATY}
model.rf <- randomForest(MyModelRFSpec, mtry = 3, data = train)
MyModelRFSpec = {ABUSEILL~ABUSEALC+ABUSEIEM+ABILLALC+ABILANAL+DEPNDILL+EDUCCAT2+EMPSTATY}
model.rf <- randomForest(MyModelRFSpec, mtry = 3, data = train)
print(summary(model.rf))
print(model.rf$importance)
predict.train.rf <- predict(model.rf, type = "prob")[,2]
predict.test.rf <- predict(model.rf, test, type = "prob")[,2]
train.rf.pred <- prediction(predict.train.rf, train$ABUSEILL)
train.rf.roc <- performance(train.rf.pred, "tpr","fpr")
train.rf.auc <- (performance(train.rf.pred, "auc"))@y.values
test.rf.pred <- prediction(predict.test.rf, test$ABUSEILL)
test.rf.roc <- performance(test.rf.pred, "tpr","fpr")
test.rf.auc <- (performance(test.rf.pred, "auc"))@y.values
# plot the ROC curves
plot(train.rf.roc, col = "darkgreen", main = "ROC Curves for Random Forest Model")
plot(test.rf.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Train: AUC=", round(train.rf.auc[[1]], digits=3))
test.legend <- paste("Test : AUC=", round(test.rf.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# RF Confusion matrix
train$dep_var<-revalue(train$ABUSEILL, c("(1) Yes (Any source variable above=1 & DEPNDILL=0)"=1, "(0) No/Unknown (Otherwise)"=0))
train$dep_var<-as.numeric(as.character(train$dep_var))
train$score <- predict(model.rf, type = "prob")[,2]
confusion_matrix(train, cutoff=0.98) # higher cutoffs than default of .5 in response score
MyModelRFSpec = {ABUSEILL~ABUSEALC+ABUSEIEM+ABILLALC+ABILANAL+EDUCCAT2+EMPSTATY}
model.rf <- randomForest(MyModelRFSpec, mtry = 3, data = train)
print(summary(model.rf))
print(model.rf$importance)
predict.train.rf <- predict(model.rf, type = "prob")[,2]
predict.test.rf <- predict(model.rf, test, type = "prob")[,2]
train.rf.pred <- prediction(predict.train.rf, train$ABUSEILL)
train.rf.roc <- performance(train.rf.pred, "tpr","fpr")
train.rf.auc <- (performance(train.rf.pred, "auc"))@y.values
test.rf.pred <- prediction(predict.test.rf, test$ABUSEILL)
test.rf.roc <- performance(test.rf.pred, "tpr","fpr")
test.rf.auc <- (performance(test.rf.pred, "auc"))@y.values
# plot the ROC curves
plot(train.rf.roc, col = "darkgreen", main = "ROC Curves for Random Forest Model")
plot(test.rf.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Train: AUC=", round(train.rf.auc[[1]], digits=3))
test.legend <- paste("Test : AUC=", round(test.rf.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# RF Confusion matrix
train$dep_var<-revalue(train$ABUSEILL, c("(1) Yes (Any source variable above=1 & DEPNDILL=0)"=1, "(0) No/Unknown (Otherwise)"=0))
train$dep_var<-as.numeric(as.character(train$dep_var))
train$score <- predict(model.rf, type = "prob")[,2]
confusion_matrix(train, cutoff=0.98) # higher cutoffs than default of .5 in response score
MyModelRFSpec = {ABUSEILL~ABUSEIEM+ABILLALC+ABILANAL+EDUCCAT2+EMPSTATY}
model.rf <- randomForest(MyModelRFSpec, mtry = 3, data = train)
print(summary(model.rf))
print(model.rf$importance)
predict.train.rf <- predict(model.rf, type = "prob")[,2]
predict.test.rf <- predict(model.rf, test, type = "prob")[,2]
train.rf.pred <- prediction(predict.train.rf, train$ABUSEILL)
train.rf.roc <- performance(train.rf.pred, "tpr","fpr")
train.rf.auc <- (performance(train.rf.pred, "auc"))@y.values
test.rf.pred <- prediction(predict.test.rf, test$ABUSEILL)
test.rf.roc <- performance(test.rf.pred, "tpr","fpr")
test.rf.auc <- (performance(test.rf.pred, "auc"))@y.values
# plot the ROC curves
plot(train.rf.roc, col = "darkgreen", main = "ROC Curves for Random Forest Model")
plot(test.rf.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Train: AUC=", round(train.rf.auc[[1]], digits=3))
test.legend <- paste("Test : AUC=", round(test.rf.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
# RF Confusion matrix
train$dep_var<-revalue(train$ABUSEILL, c("(1) Yes (Any source variable above=1 & DEPNDILL=0)"=1, "(0) No/Unknown (Otherwise)"=0))
train$dep_var<-as.numeric(as.character(train$dep_var))
train$score <- predict(model.rf, type = "prob")[,2]
confusion_matrix(train, cutoff=0.5) # higher cutoffs than default of .5 in response score
confusion_matrix(train, cutoff=0.3) # higher cutoffs than default of .5 in response score
confusion_matrix(train, cutoff=0.1) # higher cutoffs than default of .5 in response score
confusion_matrix(train, cutoff=0.6) # higher cutoffs than default of .5 in response score
confusion_matrix(train, cutoff=0.7) # higher cutoffs than default of .5 in response score
confusion_matrix(train, cutoff=0.8) # higher cutoffs than default of .5 in response score
confusion_matrix(train, cutoff=0.5) # higher cutoffs than default of .5 in response score
model.logistic.2 <- glm(MyModelRFSpec,
family = binomial(link=logit), data = train)
print(summary(model.logistic.2))
# Coefficients
round(exp(cbind(Estimate=coef(model.logistic.2),confint(model.logistic.2))),2)
# get predictions from model
predict.train.logistic <- predict(model.logistic, type = "response")
predict.test.logistic <- predict(model.logistic, test, type = "response")
train.logistic.pred <- prediction(predict.train.logistic, train$ABUSEILL)
train.logistic.roc <- performance(train.logistic.pred, "tpr","fpr")
train.logistic.auc <- (performance(train.logistic.pred, "auc"))@y.values
test.logistic.pred <- prediction(predict.test.logistic, test$ABUSEILL)
test.logistic.roc <- performance(test.logistic.pred, "tpr","fpr")
test.logistic.auc <- (performance(test.logistic.pred, "auc"))@y.values
# plot the ROC curves
plot(train.logistic.roc, col = "darkgreen", main = "ROC Curves for Logistic Regression Model")
plot(test.logistic.roc, col = "red",  add = TRUE)
abline(c(0,1))
# Draw a legend.
train.legend <- paste("Train: AUC=", round(train.logistic.auc[[1]], digits=3))
test.legend <- paste("Test : AUC=", round(test.logistic.auc[[1]], digits=3))
legend(0.6, 0.5, c(train.legend,test.legend), c(3,2))
